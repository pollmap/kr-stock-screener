"""
FRED API ìˆ˜ì§‘ê¸° (ìˆ˜ì •íŒ)
- ìœ íš¨í•œ ì‹œë¦¬ì¦ˆ IDë§Œ ì‚¬ìš©
- ì¡´ìž¬í•˜ì§€ ì•ŠëŠ” ì‹œë¦¬ì¦ˆ ì œê±°
"""

import requests
import pandas as pd
from typing import Optional, List, Dict
import logging
import time

from .base_collector import BaseCollector, retry

logger = logging.getLogger("kr_stock_collector.fred")


class FREDCollector(BaseCollector):
    """FRED API ìˆ˜ì§‘ê¸° (ê²€ì¦ëœ ì‹œë¦¬ì¦ˆë§Œ)"""
    
    BASE_URL = "https://api.stlouisfed.org/fred"
    
    # ê²€ì¦ëœ ì‹œë¦¬ì¦ˆ IDë§Œ í¬í•¨
    SERIES = {
        # ë¯¸êµ­ ê¸ˆë¦¬ (ê²€ì¦ë¨)
        'Fed_Funds': 'FEDFUNDS',
        'ë¯¸êµ­ì±„_3M': 'DGS3MO',
        'ë¯¸êµ­ì±„_2Y': 'DGS2',
        'ë¯¸êµ­ì±„_5Y': 'DGS5',
        'ë¯¸êµ­ì±„_10Y': 'DGS10',
        'ë¯¸êµ­ì±„_30Y': 'DGS30',
        '10Y-2Y_ìŠ¤í”„ë ˆë“œ': 'T10Y2Y',
        '10Y-3M_ìŠ¤í”„ë ˆë“œ': 'T10Y3M',
        '5Y_Breakeven': 'T5YIE',
        
        # ë³€ë™ì„± (ê²€ì¦ë¨)
        'VIX': 'VIXCLS',
        
        # ì›ìžìž¬ (ê²€ì¦ë¨)
        'WTI_ì›ìœ ': 'DCOILWTICO',
        'Brent_ì›ìœ ': 'DCOILBRENTEU',
        'ì²œì—°ê°€ìŠ¤': 'DHHNGSP',
        'êµ¬ë¦¬': 'PCOPPUSDM',
        
        # í™˜ìœ¨ (ê²€ì¦ë¨)
        'ë‹¬ëŸ¬ì¸ë±ìŠ¤': 'DTWEXBGS',
        'EUR_USD': 'DEXUSEU',
        'USD_JPY': 'DEXJPUS',
        'USD_KRW': 'DEXKOUS',
        'USD_CNY': 'DEXCHUS',
        
        # ë¯¸êµ­ ê²½ì œ (ê²€ì¦ë¨)
        'ë¯¸êµ­_GDP': 'GDP',
        'ë¯¸êµ­_CPI': 'CPIAUCSL',
        'ë¯¸êµ­_Core_CPI': 'CPILFESL',
        'ë¯¸êµ­_ì‹¤ì—…ë¥ ': 'UNRATE',
        'ë¯¸êµ­_ì‚°ì—…ìƒì‚°': 'INDPRO',
        
        # ì‹ ìš© (ê²€ì¦ë¨)
        'High_Yield_ìŠ¤í”„ë ˆë“œ': 'BAMLH0A0HYM2',
        'IG_ìŠ¤í”„ë ˆë“œ': 'BAMLC0A0CM',
    }
    
    # ì¹´í…Œê³ ë¦¬
    CATEGORIES = {
        'ë¯¸êµ­ê¸ˆë¦¬': ['Fed_Funds', 'ë¯¸êµ­ì±„_2Y', 'ë¯¸êµ­ì±„_5Y', 'ë¯¸êµ­ì±„_10Y', 'ë¯¸êµ­ì±„_30Y',
                   '10Y-2Y_ìŠ¤í”„ë ˆë“œ', '10Y-3M_ìŠ¤í”„ë ˆë“œ'],
        'ë³€ë™ì„±': ['VIX'],
        'ì›ìžìž¬': ['WTI_ì›ìœ ', 'Brent_ì›ìœ ', 'ì²œì—°ê°€ìŠ¤', 'êµ¬ë¦¬'],
        'í™˜ìœ¨': ['ë‹¬ëŸ¬ì¸ë±ìŠ¤', 'EUR_USD', 'USD_JPY', 'USD_KRW'],
        'ë¯¸êµ­ê²½ì œ': ['ë¯¸êµ­_GDP', 'ë¯¸êµ­_CPI', 'ë¯¸êµ­_ì‹¤ì—…ë¥ ', 'ë¯¸êµ­_ì‚°ì—…ìƒì‚°'],
        'ì‹ ìš©ìŠ¤í”„ë ˆë“œ': ['High_Yield_ìŠ¤í”„ë ˆë“œ', 'IG_ìŠ¤í”„ë ˆë“œ'],
    }
    
    def __init__(self, api_key: str, cache_dir: str = "cache"):
        super().__init__(
            name="fred",
            cache_dir=cache_dir,
            cache_expiry_days=1,
            rate_limit_per_minute=120
        )
        self.api_key = api_key
    
    @retry(max_attempts=2, delay=0.5)
    def get_series(
        self,
        series_id: str,
        start_date: str,
        end_date: str
    ) -> Optional[pd.DataFrame]:
        """FRED ì‹œë¦¬ì¦ˆ ì¡°íšŒ"""
        cache_key = f"series_{series_id}_{start_date}_{end_date}"
        cached = self._get_from_cache(cache_key)
        if cached is not None:
            return pd.DataFrame(cached)
        
        url = f"{self.BASE_URL}/series/observations"
        params = {
            'series_id': series_id,
            'api_key': self.api_key,
            'observation_start': start_date,
            'observation_end': end_date,
            'file_type': 'json'
        }
        
        try:
            response = self._make_request('GET', url, params=params, timeout=30)
            data = response.json()
            
            if 'observations' in data:
                observations = data['observations']
                if not observations:
                    return None
                
                df = pd.DataFrame(observations)
                df['value'] = pd.to_numeric(df['value'], errors='coerce')
                df['series_id'] = series_id
                df = df[['date', 'value', 'series_id']]
                
                self._save_to_cache(cache_key, df.to_dict('records'))
                return df
            else:
                return None
                
        except Exception as e:
            self.logger.warning(f"FRED [{series_id}]: {e}")
            return None
    
    def get_indicator(self, name: str, start: str, end: str) -> Optional[pd.DataFrame]:
        """ë‹¨ì¼ ì§€í‘œ ì¡°íšŒ"""
        if name not in self.SERIES:
            return None
        
        series_id = self.SERIES[name]
        df = self.get_series(series_id, start, end)
        if df is not None:
            df['indicator'] = name
        return df
    
    def collect_category(self, category: str, start: str, end: str) -> pd.DataFrame:
        """ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘"""
        if category not in self.CATEGORIES:
            return pd.DataFrame()
        
        indicators = self.CATEGORIES[category]
        all_data = []
        
        for ind in indicators:
            self.logger.info(f"  ìˆ˜ì§‘: {ind}")
            df = self.get_indicator(ind, start, end)
            if df is not None and not df.empty:
                df['category'] = category
                all_data.append(df)
            time.sleep(0.05)
        
        return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()
    
    def collect_all_indicators(
        self,
        start_date: str,
        end_date: str,
        categories: List[str] = None
    ) -> pd.DataFrame:
        """ì „ì²´ ì§€í‘œ ìˆ˜ì§‘"""
        if categories is None:
            categories = list(self.CATEGORIES.keys())
        
        all_data = []
        for cat in categories:
            self.logger.info(f"ðŸŒ {cat} ì§€í‘œ ìˆ˜ì§‘ ì¤‘...")
            df = self.collect_category(cat, start_date, end_date)
            if not df.empty:
                all_data.append(df)
        
        if not all_data:
            return pd.DataFrame()
        
        result = pd.concat(all_data, ignore_index=True)
        self.logger.info(f"âœ“ ì´ {len(result)} í–‰ ê¸€ë¡œë²Œ ì§€í‘œ ìˆ˜ì§‘")
        return result
    
    def get_available_indicators(self) -> Dict[str, List[str]]:
        return self.CATEGORIES
    
    def collect(self, start: str, end: str, categories: List[str] = None) -> pd.DataFrame:
        return self.collect_all_indicators(start, end, categories)
