"""
í•œêµ­ì€í–‰ ê²½ì œí†µê³„ì‹œìŠ¤í…œ API (Pro-Level)
30ê°œ+ êµ­ë‚´ ê±°ì‹œê²½ì œ ì§€í‘œ:
- ê¸ˆë¦¬ (8ê°œ)
- ë¬¼ê°€ (5ê°œ)
- í†µí™” (5ê°œ)
- ê²½ê¸° (6ê°œ)
- ë¬´ì—­ (4ê°œ)
- ê³ ìš© (3ê°œ)
"""

import requests
import pandas as pd
from typing import Optional, List, Dict
import logging
import time

from .base_collector import BaseCollector, retry

logger = logging.getLogger("kr_stock_collector.bok")


class BOKCollector(BaseCollector):
    """
    í•œêµ­ì€í–‰ ê²½ì œí†µê³„ì‹œìŠ¤í…œ API ìˆ˜ì§‘ê¸° (Pro-Level)
    
    30ê°œ+ êµ­ë‚´ ê±°ì‹œê²½ì œ ì§€í‘œ ìˆ˜ì§‘
    """
    
    BASE_URL = "https://ecos.bok.or.kr/api"
    
    # =====================================
    # ì£¼ìš” í†µê³„í‘œ ì½”ë“œ (í™•ì¥íŒ)
    # =====================================
    STAT_CODES = {
        # ê¸ˆë¦¬ (8ê°œ)
        'ê¸°ì¤€ê¸ˆë¦¬': ('722Y001', '0101000', 'M'),
        'ì½œê¸ˆë¦¬_1ì¼': ('817Y002', 'D21A00', 'D'),
        'CDê¸ˆë¦¬_91ì¼': ('817Y002', 'D12B10', 'D'),
        'CPê¸ˆë¦¬_91ì¼': ('817Y002', 'D14A10', 'D'),
        'êµ­ê³ ì±„_1ë…„': ('817Y002', 'D46A11', 'D'),
        'êµ­ê³ ì±„_3ë…„': ('817Y002', 'D46A13', 'D'),
        'êµ­ê³ ì±„_5ë…„': ('817Y002', 'D46A15', 'D'),
        'êµ­ê³ ì±„_10ë…„': ('817Y002', 'D46A10', 'D'),
        'íšŒì‚¬ì±„_AA-': ('817Y002', 'D53A00', 'D'),
        'íšŒì‚¬ì±„_BBB-': ('817Y002', 'D53B00', 'D'),
        'ê°€ê³„ëŒ€ì¶œê¸ˆë¦¬': ('121Y006', 'BEEALB', 'M'),
        'ê¸°ì—…ëŒ€ì¶œê¸ˆë¦¬': ('121Y006', 'BEEALA', 'M'),
        
        # ë¬¼ê°€ (5ê°œ)
        'CPI': ('901Y009', '0', 'M'),
        'CPI_ê·¼ì›': ('901Y010', 'DA', 'M'),
        'PPI': ('404Y014', '*AA', 'M'),
        'ìˆ˜ì¶œë¬¼ê°€ì§€ìˆ˜': ('401Y015', '*AA', 'M'),
        'ìˆ˜ì…ë¬¼ê°€ì§€ìˆ˜': ('401Y016', '*AA', 'M'),
        
        # í†µí™”ëŸ‰ (5ê°œ)
        'M1': ('101Y004', 'BBGS00', 'M'),
        'M2': ('101Y004', 'BBHS00', 'M'),
        'Lf': ('101Y004', 'BBJS00', 'M'),
        'ë³¸ì›í†µí™”': ('101Y003', 'BBKS00', 'M'),
        'ê°€ê³„ì‹ ìš©': ('151Y001', 'I05A0A', 'Q'),
        'ê¸°ì—…ëŒ€ì¶œ': ('104Y034', 'BBBA10', 'M'),
        
        # ê²½ê¸°/ì‹¬ë¦¬ (6ê°œ)
        'ê²½ê¸°ì„ í–‰ì§€ìˆ˜': ('901Y067', 'I16E', 'M'),
        'ê²½ê¸°ë™í–‰ì§€ìˆ˜': ('901Y067', 'I16C', 'M'),
        'ê²½ê¸°í›„í–‰ì§€ìˆ˜': ('901Y067', 'I16L', 'M'),
        'ì†Œë¹„ìì‹¬ë¦¬ì§€ìˆ˜': ('511Y002', 'FME', 'M'),
        'ê¸°ì—…ê²½ê¸°ì‹¤ì‚¬ì§€ìˆ˜_ì œì¡°ì—…': ('512Y007', 'BA', 'M'),
        'ê¸°ì—…ê²½ê¸°ì‹¤ì‚¬ì§€ìˆ˜_ë¹„ì œì¡°ì—…': ('512Y007', 'NA', 'M'),
        
        # ë¬´ì—­/êµ­ì œìˆ˜ì§€ (4ê°œ)
        'ìˆ˜ì¶œê¸ˆì•¡': ('403Y003', '110', 'M'),
        'ìˆ˜ì…ê¸ˆì•¡': ('403Y003', '120', 'M'),
        'ë¬´ì—­ìˆ˜ì§€': ('403Y003', '100', 'M'),
        'ê²½ìƒìˆ˜ì§€': ('301Y013', 'CA', 'M'),
        
        # ê³ ìš© (3ê°œ)
        'ì‹¤ì—…ë¥ ': ('901Y027', '36301', 'M'),
        'ê³ ìš©ë¥ ': ('901Y027', '36201', 'M'),
        'ê²½ì œí™œë™ì°¸ê°€ìœ¨': ('901Y027', '36101', 'M'),
        
        # í™˜ìœ¨ (4ê°œ)
        'ì›ë‹¬ëŸ¬í™˜ìœ¨': ('731Y003', '0000001', 'D'),
        'ì›ì—”í™˜ìœ¨': ('731Y003', '0000002', 'D'),
        'ì›ìœ ë¡œí™˜ìœ¨': ('731Y003', '0000003', 'D'),
        'ì›ìœ„ì•ˆí™˜ìœ¨': ('731Y003', '0000053', 'D'),
        
        # ë¶€ë™ì‚° (2ê°œ)
        'ì£¼íƒë§¤ë§¤ê°€ê²©ì§€ìˆ˜': ('901Y062', 'P63AA', 'M'),
        'ì „ì„¸ê°€ê²©ì§€ìˆ˜': ('901Y062', 'P64AA', 'M'),
        
        # ì‚°ì—…ìƒì‚° (2ê°œ)
        'ê´‘ê³µì—…ìƒì‚°ì§€ìˆ˜': ('901Y033', 'I31A', 'M'),
        'ì„œë¹„ìŠ¤ì—…ìƒì‚°ì§€ìˆ˜': ('901Y033', 'I33A', 'M'),
    }
    
    # ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í•‘
    CATEGORIES = {
        'ê¸ˆë¦¬': ['ê¸°ì¤€ê¸ˆë¦¬', 'ì½œê¸ˆë¦¬_1ì¼', 'CDê¸ˆë¦¬_91ì¼', 'êµ­ê³ ì±„_3ë…„', 'êµ­ê³ ì±„_10ë…„', 
                'íšŒì‚¬ì±„_AA-', 'ê°€ê³„ëŒ€ì¶œê¸ˆë¦¬', 'ê¸°ì—…ëŒ€ì¶œê¸ˆë¦¬'],
        'ë¬¼ê°€': ['CPI', 'CPI_ê·¼ì›', 'PPI', 'ìˆ˜ì¶œë¬¼ê°€ì§€ìˆ˜', 'ìˆ˜ì…ë¬¼ê°€ì§€ìˆ˜'],
        'í†µí™”': ['M1', 'M2', 'Lf', 'ë³¸ì›í†µí™”', 'ê°€ê³„ì‹ ìš©'],
        'ê²½ê¸°': ['ê²½ê¸°ì„ í–‰ì§€ìˆ˜', 'ê²½ê¸°ë™í–‰ì§€ìˆ˜', 'ì†Œë¹„ìì‹¬ë¦¬ì§€ìˆ˜', 'ê¸°ì—…ê²½ê¸°ì‹¤ì‚¬ì§€ìˆ˜_ì œì¡°ì—…'],
        'ë¬´ì—­': ['ìˆ˜ì¶œê¸ˆì•¡', 'ìˆ˜ì…ê¸ˆì•¡', 'ë¬´ì—­ìˆ˜ì§€', 'ê²½ìƒìˆ˜ì§€'],
        'ê³ ìš©': ['ì‹¤ì—…ë¥ ', 'ê³ ìš©ë¥ ', 'ê²½ì œí™œë™ì°¸ê°€ìœ¨'],
        'í™˜ìœ¨': ['ì›ë‹¬ëŸ¬í™˜ìœ¨', 'ì›ì—”í™˜ìœ¨', 'ì›ìœ ë¡œí™˜ìœ¨'],
        'ë¶€ë™ì‚°': ['ì£¼íƒë§¤ë§¤ê°€ê²©ì§€ìˆ˜', 'ì „ì„¸ê°€ê²©ì§€ìˆ˜'],
    }
    
    def __init__(self, api_key: str, cache_dir: str = "cache"):
        super().__init__(
            name="bok",
            cache_dir=cache_dir,
            cache_expiry_days=1,
            rate_limit_per_minute=50
        )
        self.api_key = api_key
    
    @retry(max_attempts=3, delay=1.0)
    def get_stat_data(
        self,
        stat_code: str,
        item_code: str,
        start_date: str,
        end_date: str,
        cycle: str = 'M'
    ) -> Optional[pd.DataFrame]:
        """
        í†µê³„ ë°ì´í„° ì¡°íšŒ
        
        Args:
            stat_code: í†µê³„í‘œ ì½”ë“œ
            item_code: í•­ëª©ì½”ë“œ
            start_date: ì‹œì‘ì¼ (YYYYMM ë˜ëŠ” YYYYMMDD)
            end_date: ì¢…ë£Œì¼
            cycle: D(ì¼), M(ì›”), Q(ë¶„ê¸°), A(ì—°)
        """
        cache_key = f"stat_{stat_code}_{item_code}_{start_date}_{end_date}_{cycle}"
        cached = self._get_from_cache(cache_key)
        if cached is not None:
            return pd.DataFrame(cached)
        
        url = f"{self.BASE_URL}/StatisticSearch/{self.api_key}/json/kr/1/1000/{stat_code}/{cycle}/{start_date}/{end_date}/{item_code}"
        
        try:
            response = self._make_request('GET', url, timeout=30)
            data = response.json()
            
            if 'StatisticSearch' in data:
                rows = data['StatisticSearch'].get('row', [])
                
                if not rows:
                    return None
                
                df = pd.DataFrame(rows)
                
                # í•„ìš” ì»¬ëŸ¼ë§Œ
                keep_cols = ['TIME', 'DATA_VALUE', 'STAT_NAME', 'ITEM_NAME1', 'UNIT_NAME']
                df = df[[c for c in keep_cols if c in df.columns]]
                
                df['DATA_VALUE'] = pd.to_numeric(df['DATA_VALUE'], errors='coerce')
                
                self._save_to_cache(cache_key, df.to_dict('records'))
                return df
            else:
                result = data.get('RESULT', {})
                self.logger.warning(f"BOK API: {result.get('MESSAGE', 'Unknown')}")
                return None
                
        except Exception as e:
            self.logger.error(f"BOK API ì‹¤íŒ¨: {e}")
            raise
    
    def get_indicator(
        self,
        indicator_name: str,
        start_date: str,
        end_date: str
    ) -> Optional[pd.DataFrame]:
        """
        ë‹¨ì¼ ì§€í‘œ ì¡°íšŒ (ê°„í¸ í•¨ìˆ˜)
        """
        if indicator_name not in self.STAT_CODES:
            self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì§€í‘œ: {indicator_name}")
            return None
        
        stat_code, item_code, cycle = self.STAT_CODES[indicator_name]
        
        df = self.get_stat_data(stat_code, item_code, start_date, end_date, cycle)
        if df is not None:
            df['indicator'] = indicator_name
        
        return df
    
    def collect_category(
        self,
        category: str,
        start_date: str,
        end_date: str
    ) -> pd.DataFrame:
        """
        ì¹´í…Œê³ ë¦¬ë³„ ì§€í‘œ ìˆ˜ì§‘
        
        Args:
            category: 'ê¸ˆë¦¬', 'ë¬¼ê°€', 'í†µí™”', 'ê²½ê¸°', 'ë¬´ì—­', 'ê³ ìš©', 'í™˜ìœ¨'
        """
        if category not in self.CATEGORIES:
            self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬: {category}")
            return pd.DataFrame()
        
        indicators = self.CATEGORIES[category]
        all_data = []
        
        for ind in indicators:
            self.logger.info(f"  ìˆ˜ì§‘: {ind}")
            df = self.get_indicator(ind, start_date, end_date)
            if df is not None and not df.empty:
                df['category'] = category
                all_data.append(df)
            time.sleep(0.1)
        
        if not all_data:
            return pd.DataFrame()
        
        return pd.concat(all_data, ignore_index=True)
    
    def collect_all_indicators(
        self,
        start_date: str,
        end_date: str,
        categories: List[str] = None
    ) -> pd.DataFrame:
        """
        ì „ì²´/ì„ íƒ ê±°ì‹œê²½ì œ ì§€í‘œ ìˆ˜ì§‘
        
        Args:
            start_date: ì‹œì‘ì›” (YYYYMM)
            end_date: ì¢…ë£Œì›”
            categories: ìˆ˜ì§‘í•  ì¹´í…Œê³ ë¦¬ (Noneì´ë©´ ì „ì²´)
        """
        if categories is None:
            categories = list(self.CATEGORIES.keys())
        
        all_data = []
        
        for cat in categories:
            self.logger.info(f"ğŸ“Š {cat} ì§€í‘œ ìˆ˜ì§‘ ì¤‘...")
            df = self.collect_category(cat, start_date, end_date)
            if not df.empty:
                all_data.append(df)
        
        if not all_data:
            return pd.DataFrame()
        
        result = pd.concat(all_data, ignore_index=True)
        self.logger.info(f"âœ“ ì´ {len(result)} í–‰ í•œêµ­ê²½ì œ ì§€í‘œ ìˆ˜ì§‘")
        
        return result
    
    def get_available_indicators(self) -> Dict[str, List[str]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì§€í‘œ ëª©ë¡ ë°˜í™˜"""
        return self.CATEGORIES
    
    def collect(self, start: str, end: str, categories: List[str] = None) -> pd.DataFrame:
        """BaseCollector ì¸í„°í˜ì´ìŠ¤"""
        return self.collect_all_indicators(start, end, categories)
